{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: **Lane Lines Detection using OpenCV** \n",
    "\n",
    "**In this project, I used Python and OpenCV to detect lane lines on the road.\n",
    "I developed a processing pipeline that works on a series of individual images, and applied the result to a video stream.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of the intended output**\n",
    "\n",
    "---\n",
    "\n",
    "<figure>\n",
    " <img src=\"output_example.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline architecture:\n",
    "-  **Load test images.**\n",
    "-  **Apply Color Selection**\n",
    "-  **Apply Canny edge detection.**\n",
    "    -  Apply gray scaling to the images.\n",
    "    -  Apply Gaussian smoothing.\n",
    "    -  Perform Canny edge detection.\n",
    "-  **Determine the region of interest.**\n",
    "-  **Apply Hough transform.**\n",
    "-  **Average and extrapolating the lane lines.**\n",
    "-  **Apply on video streams.**\n",
    "\n",
    "I'll explain each step in details below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environement:\n",
    "-  Windows 7\n",
    "-  Anaconda 4.3.29\n",
    "-  Python 3.6.2\n",
    "-  OpenCV 3.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 6 test images. We will write a function called `list_images()` that will show all the test images we're working on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images(images, cols = 2, rows = 5, cmap=None):\n",
    "    \"\"\"\n",
    "    Display a list of images in a single figure with matplotlib.\n",
    "        Parameters:\n",
    "            images: List of np.arrays compatible with plt.imshow.\n",
    "            cols (Default = 2): Number of columns in the figure.\n",
    "            rows (Default = 5): Number of rows in the figure.\n",
    "            cmap (Default = None): Used to display gray images.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 11))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        #Use gray scale color map if there is only one channel\n",
    "        \n",
    "        cmap = 'gray' if len(image.shape) == 2 else cmap\n",
    "        plt.imshow(image, cmap = cmap)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    #plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the test images\n",
    "test_images = [plt.imread(img) for img in glob.glob('test_images/*.jpg')]\n",
    "list_images(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wikipedia**: The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Gray scaling the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Canny edge detection algorithm measures the intensity gradients of each pixel. So, we need to convert the images into gray scale in order to detect edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_scale(image):\n",
    "    \"\"\"\n",
    "    Convert images to gray scale.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_images = list(map(gray_scale, color_selected_images))\n",
    "list_images(gray_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Applying Gaussian smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wikipedia**: Since all edge detection results are easily affected by image noise, it is essential to filter out the noise to prevent false detection caused by noise. To smooth the image, a Gaussian filter is applied to convolve with the image. This step will slightly smooth the image to reduce the effects of obvious noise on the edge detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_smoothing(image, kernel_size = 13):\n",
    "    \"\"\"\n",
    "    Apply Gaussian filter to the input image.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "            kernel_size (Default = 13): The size of the Gaussian kernel will affect the performance of the detector.\n",
    "            It must be an odd number (3, 5, 7, ...).\n",
    "    \"\"\"\n",
    "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_images = list(map(gaussian_smoothing, gray_images))\n",
    "list_images(blur_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Applying Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wikipedia**:\n",
    "The Process of Canny edge detection algorithm can be broken down to 5 different steps:\n",
    "1. Find the intensity gradients of the image\n",
    "2. Apply non-maximum suppression to get rid of spurious response to edge detection.\n",
    "3. Apply *double threshold* to determine potential edges.\n",
    "4. Track edge by hysteresis: Finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges.\n",
    "\n",
    "**If an edge pixel’s gradient value is higher than the high threshold value, it is marked as a strong edge pixel. If an edge pixel’s gradient value is smaller than the high threshold value and larger than the low threshold value, it is marked as a weak edge pixel. If an edge pixel's value is smaller than the low threshold value, it will be suppressed.\n",
    "The two threshold values are empirically determined and their definition will depend on the content of a given input image.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_detector(image, low_threshold = 50, high_threshold = 150):\n",
    "    \"\"\"\n",
    "    Apply Canny Edge Detection algorithm to the input image.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "            low_threshold (Default = 50).\n",
    "            high_threshold (Default = 150).\n",
    "    \"\"\"\n",
    "    return cv2.Canny(image, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_detected_images = list(map(canny_detector, blur_images))\n",
    "list_images(edge_detected_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Region of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're interested in the area facing the camera, where the lane lines are found. So, we'll apply region masking to cut out everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_selection(image):\n",
    "    \"\"\"\n",
    "    Determine and cut the region of interest in the input image.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(image)   \n",
    "    #Defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(image.shape) > 2:\n",
    "        channel_count = image.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    #We could have used fixed numbers as the vertices of the polygon,\n",
    "    #but they will not be applicable to images with different dimesnions.\n",
    "    rows, cols = image.shape[:2]\n",
    "    bottom_left  = [cols * 0.1, rows * 0.95]\n",
    "    top_left     = [cols * 0.4, rows * 0.6]\n",
    "    bottom_right = [cols * 0.9, rows * 0.95]\n",
    "    top_right    = [cols * 0.6, rows * 0.6]\n",
    "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = list(map(region_selection, edge_detected_images))\n",
    "list_images(masked_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hough Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hough transform is a technique which can be used to isolate features of a particular shape within an image. I'll use it to detected the lane lines in `selected_region_images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_transform(image):\n",
    "    \"\"\"\n",
    "    Determine and cut the region of interest in the input image.\n",
    "        Parameters:\n",
    "            image: The output of a Canny transform.\n",
    "    \"\"\"\n",
    "    rho = 1              #Distance resolution of the accumulator in pixels.\n",
    "    theta = np.pi/180    #Angle resolution of the accumulator in radians.\n",
    "    threshold = 20       #Only lines that are greater than threshold will be returned.\n",
    "    minLineLength = 20   #Line segments shorter than that are rejected.\n",
    "    maxLineGap = 300     #Maximum allowed gap between points on the same line to link them\n",
    "    return cv2.HoughLinesP(image, rho = rho, theta = theta, threshold = threshold,\n",
    "                           minLineLength = minLineLength, maxLineGap = maxLineGap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hough_lines` contains the list of lines detected in the selected region. Now, we will draw these detected lines onto the original `test_images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hough_lines = list(map(hough_transform, masked_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(image, lines, color = [255, 0, 0], thickness = 2):\n",
    "    \"\"\"\n",
    "    Draw lines onto the input image.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "            lines: The lines we want to draw.\n",
    "            color (Default = red): Line color.\n",
    "            thickness (Default = 2): Line thickness.\n",
    "    \"\"\"\n",
    "    image = np.copy(image)\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_images = []\n",
    "for image, lines in zip(test_images, hough_lines):\n",
    "    line_images.append(draw_lines(image, lines))\n",
    "    \n",
    "list_images(line_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Averaging and extrapolating the lane lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have multiple lines detected for each lane line. We need to average all these lines and draw a single line for each lane line.\n",
    "We also need to extrapolate the lane lines to cover the full lane line length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_slope_intercept(lines):\n",
    "    \"\"\"\n",
    "    Find the slope and intercept of the left and right lanes of each image.\n",
    "        Parameters:\n",
    "            lines: The output lines from Hough Transform.\n",
    "    \"\"\"\n",
    "    left_lines    = [] #(slope, intercept)\n",
    "    left_weights  = [] #(length,)\n",
    "    right_lines   = [] #(slope, intercept)\n",
    "    right_weights = [] #(length,)\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            if x1 == x2:\n",
    "                continue\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            intercept = y1 - (slope * x1)\n",
    "            length = np.sqrt(((y2 - y1) ** 2) + ((x2 - x1) ** 2))\n",
    "            if slope < 0:\n",
    "                left_lines.append((slope, intercept))\n",
    "                left_weights.append((length))\n",
    "            else:\n",
    "                right_lines.append((slope, intercept))\n",
    "                right_weights.append((length))\n",
    "    left_lane  = np.dot(left_weights,  left_lines) / np.sum(left_weights)  if len(left_weights) > 0 else None\n",
    "    right_lane = np.dot(right_weights, right_lines) / np.sum(right_weights) if len(right_weights) > 0 else None\n",
    "    return left_lane, right_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_points(y1, y2, line):\n",
    "    \"\"\"\n",
    "    Converts the slope and intercept of each line into pixel points.\n",
    "        Parameters:\n",
    "            y1: y-value of the line's starting point.\n",
    "            y2: y-value of the line's end point.\n",
    "            line: The slope and intercept of the line.\n",
    "    \"\"\"\n",
    "    if line is None:\n",
    "        return None\n",
    "    slope, intercept = line\n",
    "    x1 = int((y1 - intercept)/slope)\n",
    "    x2 = int((y2 - intercept)/slope)\n",
    "    y1 = int(y1)\n",
    "    y2 = int(y2)\n",
    "    return ((x1, y1), (x2, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_lines(image, lines):\n",
    "    \"\"\"\n",
    "    Create full lenght lines from pixel points.\n",
    "        Parameters:\n",
    "            image: The input test image.\n",
    "            lines: The output lines from Hough Transform.\n",
    "    \"\"\"\n",
    "    left_lane, right_lane = average_slope_intercept(lines)\n",
    "    y1 = image.shape[0]\n",
    "    y2 = y1 * 0.6\n",
    "    left_line  = pixel_points(y1, y2, left_lane)\n",
    "    right_line = pixel_points(y1, y2, right_lane)\n",
    "    return left_line, right_line\n",
    "\n",
    "    \n",
    "def draw_lane_lines(image, lines, color=[255, 0, 0], thickness=12):\n",
    "    \"\"\"\n",
    "    Draw lines onto the input image.\n",
    "        Parameters:\n",
    "            image: The input test image.\n",
    "            lines: The output lines from Hough Transform.\n",
    "            color (Default = red): Line color.\n",
    "            thickness (Default = 12): Line thickness. \n",
    "    \"\"\"\n",
    "    line_image = np.zeros_like(image)\n",
    "    for line in lines:\n",
    "        if line is not None:\n",
    "            cv2.line(line_image, *line,  color, thickness)\n",
    "    return cv2.addWeighted(image, 1.0, line_image, 1.0, 0.0)\n",
    "             \n",
    "    \n",
    "lane_images = []\n",
    "for image, lines in zip(test_images, hough_lines):\n",
    "    lane_images.append(draw_lane_lines(image, lane_lines(image, lines)))\n",
    "\n",
    "    \n",
    "list_images(lane_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply on video streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use the above functions to detect lane lines from a video stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import everything needed to edit/save/watch video clips\n",
    "from moviepy import *\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_processor(image):\n",
    "    \"\"\"\n",
    "    Process the input frame to detect lane lines.\n",
    "        Parameters:\n",
    "            image: Single video frame.\n",
    "    \"\"\"\n",
    "    color_select = HSL_color_selection(image)\n",
    "    gray         = gray_scale(color_select)\n",
    "    smooth       = gaussian_smoothing(gray)\n",
    "    edges        = canny_detector(smooth)\n",
    "    region       = region_selection(edges)\n",
    "    hough        = hough_transform(region)\n",
    "    result       = draw_lane_lines(image, lane_lines(image, hough))\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(test_video, output_video):\n",
    "    \"\"\"\n",
    "    Read input video stream and produce a video file with detected lane lines.\n",
    "        Parameters:\n",
    "            test_video: Input video.\n",
    "            output_video: A video file with detected lane lines.\n",
    "    \"\"\"\n",
    "    input_video = VideoFileClip(os.path.join('test_videos', test_video), audio=False)\n",
    "    processed = input_video.fl_image(frame_processor)\n",
    "    processed.write_videofile(os.path.join('output_videos', output_video), audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time process_video('solidWhiteRight.mp4', 'solidWhiteRight_output.mp4')\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"output_videos\\solidWhiteRight_output.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time process_video('solidYellowLeft.mp4', 'solidYellowLeft_output.mp4')\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"output_videos\\solidYellowLeft_output.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time process_video('challenge.mp4', 'challenge_output.mp4')\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"output_videos\\challenge_output.mp4\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
